import logging
import json
import hashlib
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import pickle
from config.settings import Config

class CacheService:
    """ê³ ì„±ëŠ¥ ìºì‹± ë° ìµœì í™” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.config = Config
        self.memory_cache = {}  # ë©”ëª¨ë¦¬ ìºì‹œ (ê°œë°œìš©)
        self.cache_stats = {
            'hits': 0,
            'misses': 0,
            'sets': 0
        }
        
        # Redis ì—°ê²° (ì‹¤ì œ í™˜ê²½ì—ì„œ ì‚¬ìš©)
        self.redis_client = None
        try:
            import redis
            self.redis_client = redis.Redis(
                host='localhost', 
                port=6379, 
                db=1,
                decode_responses=True,
                socket_timeout=5,  # íƒ€ì„ì•„ì›ƒ ì¦ê°€
                socket_connect_timeout=5,
                retry_on_timeout=True,
                health_check_interval=30
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self.redis_client.ping()
            
            # Redis ì •ë³´ ì¡°íšŒ
            redis_info = self.redis_client.info()
            redis_version = redis_info.get('redis_version', 'unknown')
            
            logging.info(f"âœ… Redis connected successfully - Version: {redis_version}")
            logging.info(f"ğŸ“Š Redis Memory: {redis_info.get('used_memory_human', 'N/A')}")
            
        except ImportError:
            logging.warning("âŒ Redis library not installed. Install with: pip install redis")
        except redis.ConnectionError as e:
            logging.warning(f"âŒ Redis connection failed: {e}")
            logging.warning("ğŸ’¡ Make sure Redis server is running: redis-server")
        except Exception as e:
            logging.warning(f"âŒ Redis initialization error: {e}")
            logging.warning("ğŸ”„ Falling back to memory cache")
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        try:
            # Redis ìš°ì„  ì‹œë„
            if self.redis_client:
                value = self.redis_client.get(key)
                if value:
                    self.cache_stats['hits'] += 1
                    return json.loads(value)
            
            # ë©”ëª¨ë¦¬ ìºì‹œ ì‹œë„
            if key in self.memory_cache:
                cache_entry = self.memory_cache[key]
                if cache_entry['expires'] > datetime.now():
                    self.cache_stats['hits'] += 1
                    return cache_entry['data']
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì œê±°
                    del self.memory_cache[key]
            
            self.cache_stats['misses'] += 1
            return None
            
        except Exception as e:
            logging.error(f"Cache get failed for key {key}: {e}")
            self.cache_stats['misses'] += 1
            return None
    
    def set(self, key: str, value: Any, expire_minutes: int = 60) -> bool:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        try:
            self.cache_stats['sets'] += 1
            
            # Redisì— ì €ì¥
            if self.redis_client:
                json_value = json.dumps(value, default=str)
                return self.redis_client.setex(key, expire_minutes * 60, json_value)
            
            # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            expires = datetime.now() + timedelta(minutes=expire_minutes)
            self.memory_cache[key] = {
                'data': value,
                'expires': expires
            }
            
            # ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 1000ê°œ)
            if len(self.memory_cache) > 1000:
                self._cleanup_memory_cache()
            
            return True
            
        except Exception as e:
            logging.error(f"Cache set failed for key {key}: {e}")
            return False
    
    def delete(self, key: str) -> bool:
        """ìºì‹œì—ì„œ ë°ì´í„° ì‚­ì œ"""
        try:
            deleted = False
            
            # Redisì—ì„œ ì‚­ì œ
            if self.redis_client:
                deleted = bool(self.redis_client.delete(key))
            
            # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì‚­ì œ
            if key in self.memory_cache:
                del self.memory_cache[key]
                deleted = True
            
            return deleted
            
        except Exception as e:
            logging.error(f"Cache delete failed for key {key}: {e}")
            return False
    
    def _cleanup_memory_cache(self):
        """ë§Œë£Œëœ ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬"""
        now = datetime.now()
        expired_keys = [
            key for key, entry in self.memory_cache.items()
            if entry['expires'] <= now
        ]
        
        for key in expired_keys:
            del self.memory_cache[key]
        
        # ì—¬ì „íˆ í¬ê¸°ê°€ í¬ë©´ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ
        if len(self.memory_cache) > 1000:
            items = list(self.memory_cache.items())
            items.sort(key=lambda x: x[1]['expires'])
            
            # ê°€ì¥ ì˜¤ë˜ëœ 200ê°œ ì‚­ì œ
            for key, _ in items[:200]:
                del self.memory_cache[key]
    
    def cache_query_result(self, query: str, params: tuple, result: Any, expire_minutes: int = 30) -> bool:
        """DB ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±"""
        cache_key = self._generate_query_cache_key(query, params)
        return self.set(cache_key, result, expire_minutes)
    
    def get_cached_query_result(self, query: str, params: tuple) -> Optional[Any]:
        """ìºì‹œëœ DB ì¿¼ë¦¬ ê²°ê³¼ ì¡°íšŒ"""
        cache_key = self._generate_query_cache_key(query, params)
        return self.get(cache_key)
    
    def _generate_query_cache_key(self, query: str, params: tuple) -> str:
        """ì¿¼ë¦¬ ìºì‹œ í‚¤ ìƒì„±"""
        query_normalized = ' '.join(query.split())  # ê³µë°± ì •ê·œí™”
        cache_input = f"{query_normalized}:{str(params)}"
        return f"query:{hashlib.md5(cache_input.encode()).hexdigest()}"
    
    def cache_ocr_result(self, image_hash: str, ocr_result: Dict, expire_hours: int = 24) -> bool:
        """OCR ê²°ê³¼ ìºì‹± (ê°™ì€ ì´ë¯¸ì§€ ì¬ì²˜ë¦¬ ë°©ì§€)"""
        cache_key = f"ocr:{image_hash}"
        return self.set(cache_key, ocr_result, expire_hours * 60)
    
    def get_cached_ocr_result(self, image_hash: str) -> Optional[Dict]:
        """ìºì‹œëœ OCR ê²°ê³¼ ì¡°íšŒ"""
        cache_key = f"ocr:{image_hash}"
        return self.get(cache_key)
    
    def cache_llm_result(self, prompt_hash: str, llm_result: Dict, expire_minutes: int = 120) -> bool:
        """LLM ê²°ê³¼ ìºì‹± (ë™ì¼ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš©)"""
        cache_key = f"llm:{prompt_hash}"
        return self.set(cache_key, llm_result, expire_minutes)
    
    def get_cached_llm_result(self, prompt_hash: str) -> Optional[Dict]:
        """ìºì‹œëœ LLM ê²°ê³¼ ì¡°íšŒ"""
        cache_key = f"llm:{prompt_hash}"
        return self.get(cache_key)
    
    def cache_account_categories(self, categories: List[Dict], expire_hours: int = 12) -> bool:
        """ê³„ì •ê³¼ëª© ëª©ë¡ ìºì‹± (ìì£¼ ì¡°íšŒë˜ëŠ” ë°ì´í„°)"""
        cache_key = "account_categories:active"
        return self.set(cache_key, categories, expire_hours * 60)
    
    def get_cached_account_categories(self) -> Optional[List[Dict]]:
        """ìºì‹œëœ ê³„ì •ê³¼ëª© ëª©ë¡ ì¡°íšŒ"""
        cache_key = "account_categories:active"
        return self.get(cache_key)
    
    def cache_user_patterns(self, user_id: str, patterns: Dict, expire_hours: int = 6) -> bool:
        """ì‚¬ìš©ì íŒ¨í„´ ìºì‹±"""
        cache_key = f"user_patterns:{user_id}"
        return self.set(cache_key, patterns, expire_hours * 60)
    
    def get_cached_user_patterns(self, user_id: str) -> Optional[Dict]:
        """ìºì‹œëœ ì‚¬ìš©ì íŒ¨í„´ ì¡°íšŒ"""
        cache_key = f"user_patterns:{user_id}"
        return self.get(cache_key)
    
    def invalidate_pattern(self, pattern: str) -> int:
        """íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”"""
        try:
            invalidated_count = 0
            
            if self.redis_client:
                # Redisì—ì„œ íŒ¨í„´ ë§¤ì¹­ í‚¤ ì°¾ê¸°
                keys = self.redis_client.keys(pattern)
                if keys:
                    invalidated_count = self.redis_client.delete(*keys)
            
            # ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ íŒ¨í„´ ë§¤ì¹­ í‚¤ ì°¾ê¸°
            matching_keys = [
                key for key in self.memory_cache.keys()
                if pattern.replace('*', '') in key
            ]
            
            for key in matching_keys:
                del self.memory_cache[key]
                invalidated_count += 1
            
            logging.info(f"Invalidated {invalidated_count} cache keys matching pattern: {pattern}")
            return invalidated_count
            
        except Exception as e:
            logging.error(f"Cache invalidation failed for pattern {pattern}: {e}")
            return 0
    
    def get_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        total_requests = self.cache_stats['hits'] + self.cache_stats['misses']
        hit_rate = (self.cache_stats['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        stats = {
            'hits': self.cache_stats['hits'],
            'misses': self.cache_stats['misses'],
            'sets': self.cache_stats['sets'],
            'hit_rate': round(hit_rate, 2),
            'memory_cache_size': len(self.memory_cache)
        }
        
        # Redis í†µê³„ ì¶”ê°€
        if self.redis_client:
            try:
                redis_info = self.redis_client.info('memory')
                stats['redis_memory_usage'] = redis_info.get('used_memory_human', 'N/A')
                stats['redis_connected'] = True
            except:
                stats['redis_connected'] = False
        else:
            stats['redis_connected'] = False
        
        return stats
    
    def warm_up_cache(self) -> Dict:
        """ìºì‹œ ì›Œë°ì—… (ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ë¯¸ë¦¬ ë¡œë”©)"""
        try:
            from services.db_service import db_service
            
            warmup_results = {
                'account_categories': False,
                'recent_patterns': False,
                'system_stats': False
            }
            
            # 1. ê³„ì •ê³¼ëª© ëª©ë¡ ìºì‹±
            try:
                categories = db_service.get_account_categories()
                if categories:
                    self.cache_account_categories(categories)
                    warmup_results['account_categories'] = True
            except Exception as e:
                logging.error(f"Failed to warm up account categories: {e}")
            
            # 2. ìµœê·¼ íŒ¨í„´ ìºì‹±
            try:
                # ìµœê·¼ 7ì¼ê°„ ìì£¼ ì‚¬ìš©ëœ íŒ¨í„´ë“¤ì„ ë¯¸ë¦¬ ìºì‹±
                # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë³µì¡í•œ ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ìºì‹±)
                recent_patterns = {"cached": True, "timestamp": datetime.now().isoformat()}
                self.set("recent_patterns:weekly", recent_patterns, 360)  # 6ì‹œê°„
                warmup_results['recent_patterns'] = True
            except Exception as e:
                logging.error(f"Failed to warm up recent patterns: {e}")
            
            # 3. ì‹œìŠ¤í…œ í†µê³„ ìºì‹±
            try:
                system_stats = {"warmed_up": True, "timestamp": datetime.now().isoformat()}
                self.set("system_stats:dashboard", system_stats, 60)  # 1ì‹œê°„
                warmup_results['system_stats'] = True
            except Exception as e:
                logging.error(f"Failed to warm up system stats: {e}")
            
            logging.info(f"Cache warmup completed: {warmup_results}")
            return warmup_results
            
        except Exception as e:
            logging.error(f"Cache warmup failed: {e}")
            return {"error": str(e)}
    
    def generate_image_hash(self, image_data: bytes) -> str:
        """ì´ë¯¸ì§€ í•´ì‹œ ìƒì„± (OCR ìºì‹±ìš©)"""
        return hashlib.sha256(image_data).hexdigest()
    
    def generate_prompt_hash(self, prompt: str) -> str:
        """í”„ë¡¬í”„íŠ¸ í•´ì‹œ ìƒì„± (LLM ìºì‹±ìš©)"""
        return hashlib.md5(prompt.encode()).hexdigest()
    
    def redis_set_with_expiry(self, key: str, value: Any, expire_seconds: int = 3600) -> bool:
        """Redis ì „ìš© ë§Œë£Œì‹œê°„ ì„¤ì •"""
        if not self.redis_client:
            return False
        
        try:
            json_value = json.dumps(value, default=str, ensure_ascii=False)
            return self.redis_client.setex(key, expire_seconds, json_value)
        except Exception as e:
            logging.error(f"Redis setex failed for key {key}: {e}")
            return False
    
    def redis_get_with_ttl(self, key: str) -> Dict:
        """Redisì—ì„œ ê°’ê³¼ TTL í•¨ê»˜ ì¡°íšŒ"""
        if not self.redis_client:
            return {"value": None, "ttl": -1, "exists": False}
        
        try:
            # íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•´ ì›ìì  ì—°ì‚°
            pipe = self.redis_client.pipeline()
            pipe.get(key)
            pipe.ttl(key)
            results = pipe.execute()
            
            value_str, ttl = results
            
            if value_str is None:
                return {"value": None, "ttl": -1, "exists": False}
            
            value = json.loads(value_str)
            return {"value": value, "ttl": ttl, "exists": True}
            
        except Exception as e:
            logging.error(f"Redis get with TTL failed for key {key}: {e}")
            return {"value": None, "ttl": -1, "exists": False}
    
    def redis_mget(self, keys: List[str]) -> Dict[str, Any]:
        """Redisì—ì„œ ì—¬ëŸ¬ í‚¤ í•œë²ˆì— ì¡°íšŒ"""
        if not self.redis_client or not keys:
            return {}
        
        try:
            values = self.redis_client.mget(keys)
            result = {}
            
            for key, value_str in zip(keys, values):
                if value_str is not None:
                    try:
                        result[key] = json.loads(value_str)
                    except json.JSONDecodeError:
                        logging.warning(f"Failed to decode JSON for key {key}")
                        result[key] = None
                else:
                    result[key] = None
            
            return result
            
        except Exception as e:
            logging.error(f"Redis mget failed: {e}")
            return {}
    
    def redis_delete_pattern(self, pattern: str) -> int:
        """Redisì—ì„œ íŒ¨í„´ ë§¤ì¹­í•˜ëŠ” í‚¤ë“¤ ì‚­ì œ"""
        if not self.redis_client:
            return 0
        
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                return self.redis_client.delete(*keys)
            return 0
            
        except Exception as e:
            logging.error(f"Redis pattern delete failed: {e}")
            return 0
    
    def get_redis_info(self) -> Dict:
        """Redis ì„œë²„ ì •ë³´ ì¡°íšŒ"""
        if not self.redis_client:
            return {"connected": False, "error": "Redis client not available"}
        
        try:
            info = self.redis_client.info()
            
            return {
                "connected": True,
                "redis_version": info.get('redis_version'),
                "used_memory": info.get('used_memory_human'),
                "connected_clients": info.get('connected_clients'),
                "total_commands_processed": info.get('total_commands_processed'),
                "uptime_in_seconds": info.get('uptime_in_seconds'),
                "keyspace": self.redis_client.info('keyspace')
            }
            
        except Exception as e:
            return {"connected": False, "error": str(e)}

# ì„±ëŠ¥ ìµœì í™” ë„ìš°ë¯¸ í´ë˜ìŠ¤
class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ë„êµ¬"""
    
    def __init__(self, cache_service: CacheService):
        self.cache = cache_service
    
    def cached_db_query(self, func, *args, expire_minutes: int = 30, **kwargs):
        """DB ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ìºì‹±í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = f"db:{func.__name__}:{hashlib.md5(str(args + tuple(kwargs.items())).encode()).hexdigest()}"
        
        # ìºì‹œì—ì„œ ë¨¼ì € ì¡°íšŒ
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰
        result = func(*args, **kwargs)
        
        # ê²°ê³¼ ìºì‹±
        self.cache.set(cache_key, result, expire_minutes)
        
        return result
    
    def batch_invalidate_user_cache(self, user_id: str):
        """ì‚¬ìš©ì ê´€ë ¨ ëª¨ë“  ìºì‹œ ë¬´íš¨í™”"""
        patterns = [
            f"user_patterns:{user_id}",
            f"user_stats:{user_id}*",
            f"user_recommendations:{user_id}*"
        ]
        
        for pattern in patterns:
            self.cache.invalidate_pattern(pattern)

class RedisCacheManager:
    """Redis ì „ìš© ê³ ì„±ëŠ¥ ìºì‹œ ë§¤ë‹ˆì €"""
    
    def __init__(self, cache_service: CacheService):
        self.cache_service = cache_service
        self.redis_client = cache_service.redis_client
        
        # ìºì‹œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.namespaces = {
            'ocr': 'receipt:ocr:',
            'llm': 'receipt:llm:',
            'user': 'receipt:user:',
            'analytics': 'receipt:analytics:',
            'categories': 'receipt:categories:',
            'session': 'receipt:session:'
        }
    
    def cache_ocr_result(self, image_hash: str, ocr_result: Dict, expire_hours: int = 24) -> bool:
        """OCR ê²°ê³¼ë¥¼ Redisì— ìºì‹± (24ì‹œê°„)"""
        if not self.redis_client:
            return False
        
        try:
            key = f"{self.namespaces['ocr']}{image_hash}"
            expire_seconds = expire_hours * 3600
            
            cache_data = {
                'ocr_result': ocr_result,
                'cached_at': datetime.now().isoformat(),
                'expires_at': (datetime.now() + timedelta(hours=expire_hours)).isoformat()
            }
            
            success = self.cache_service.redis_set_with_expiry(key, cache_data, expire_seconds)
            
            if success:
                logging.info(f"âœ… OCR result cached: {key} (expires in {expire_hours}h)")
            
            return success
            
        except Exception as e:
            logging.error(f"âŒ OCR caching failed: {e}")
            return False
    
    def get_cached_ocr_result(self, image_hash: str) -> Optional[Dict]:
        """ìºì‹œëœ OCR ê²°ê³¼ ì¡°íšŒ"""
        if not self.redis_client:
            return None
        
        try:
            key = f"{self.namespaces['ocr']}{image_hash}"
            cache_data = self.cache_service.redis_get_with_ttl(key)
            
            if cache_data['exists']:
                logging.info(f"ğŸ¯ OCR cache hit: {key} (TTL: {cache_data['ttl']}s)")
                return cache_data['value']['ocr_result']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ OCR cache retrieval failed: {e}")
            return None
    
    def cache_llm_response(self, prompt_hash: str, llm_response: Dict, expire_minutes: int = 120) -> bool:
        """LLM ì‘ë‹µì„ Redisì— ìºì‹± (2ì‹œê°„)"""
        if not self.redis_client:
            return False
        
        try:
            key = f"{self.namespaces['llm']}{prompt_hash}"
            expire_seconds = expire_minutes * 60
            
            cache_data = {
                'llm_response': llm_response,
                'model_used': 'gpt-3.5-turbo',  # ì‹¤ì œ ì‚¬ìš©ëœ ëª¨ë¸
                'cached_at': datetime.now().isoformat(),
                'prompt_hash': prompt_hash
            }
            
            success = self.cache_service.redis_set_with_expiry(key, cache_data, expire_seconds)
            
            if success:
                logging.info(f"âœ… LLM response cached: {key} (expires in {expire_minutes}m)")
            
            return success
            
        except Exception as e:
            logging.error(f"âŒ LLM caching failed: {e}")
            return False
    
    def get_cached_llm_response(self, prompt_hash: str) -> Optional[Dict]:
        """ìºì‹œëœ LLM ì‘ë‹µ ì¡°íšŒ"""
        if not self.redis_client:
            return None
        
        try:
            key = f"{self.namespaces['llm']}{prompt_hash}"
            cache_data = self.cache_service.redis_get_with_ttl(key)
            
            if cache_data['exists']:
                logging.info(f"ğŸ¯ LLM cache hit: {key} (TTL: {cache_data['ttl']}s)")
                return cache_data['value']['llm_response']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ LLM cache retrieval failed: {e}")
            return None
    
    def cache_user_session(self, session_id: str, user_data: Dict, expire_minutes: int = 60) -> bool:
        """ì‚¬ìš©ì ì„¸ì…˜ ì •ë³´ ìºì‹±"""
        if not self.redis_client:
            return False
        
        try:
            key = f"{self.namespaces['session']}{session_id}"
            expire_seconds = expire_minutes * 60
            
            session_data = {
                'user_data': user_data,
                'last_activity': datetime.now().isoformat(),
                'session_id': session_id
            }
            
            return self.cache_service.redis_set_with_expiry(key, session_data, expire_seconds)
            
        except Exception as e:
            logging.error(f"âŒ Session caching failed: {e}")
            return False
    
    def get_cached_user_session(self, session_id: str) -> Optional[Dict]:
        """ìºì‹œëœ ì‚¬ìš©ì ì„¸ì…˜ ì¡°íšŒ"""
        if not self.redis_client:
            return None
        
        try:
            key = f"{self.namespaces['session']}{session_id}"
            cache_data = self.cache_service.redis_get_with_ttl(key)
            
            if cache_data['exists']:
                return cache_data['value']['user_data']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ Session retrieval failed: {e}")
            return None
    
    def cache_analytics_data(self, cache_key: str, analytics_result: Dict, expire_minutes: int = 30) -> bool:
        """ë¶„ì„ ê²°ê³¼ ìºì‹±"""
        if not self.redis_client:
            return False
        
        try:
            key = f"{self.namespaces['analytics']}{cache_key}"
            expire_seconds = expire_minutes * 60
            
            cache_data = {
                'analytics_result': analytics_result,
                'generated_at': datetime.now().isoformat(),
                'cache_key': cache_key
            }
            
            return self.cache_service.redis_set_with_expiry(key, cache_data, expire_seconds)
            
        except Exception as e:
            logging.error(f"âŒ Analytics caching failed: {e}")
            return False
    
    def get_cached_analytics_data(self, cache_key: str) -> Optional[Dict]:
        """ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.redis_client:
            return None
        
        try:
            key = f"{self.namespaces['analytics']}{cache_key}"
            cache_data = self.cache_service.redis_get_with_ttl(key)
            
            if cache_data['exists']:
                return cache_data['value']['analytics_result']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ Analytics retrieval failed: {e}")
            return None
    
    def batch_cache_account_categories(self, categories: List[Dict]) -> bool:
        """ê³„ì •ê³¼ëª© ëª©ë¡ì„ Redisì— ë°°ì¹˜ ìºì‹±"""
        if not self.redis_client or not categories:
            return False
        
        try:
            # ì „ì²´ ëª©ë¡ ìºì‹±
            key = f"{self.namespaces['categories']}all"
            expire_seconds = 12 * 3600  # 12ì‹œê°„
            
            cache_data = {
                'categories': categories,
                'total_count': len(categories),
                'cached_at': datetime.now().isoformat()
            }
            
            success = self.cache_service.redis_set_with_expiry(key, cache_data, expire_seconds)
            
            # ê°œë³„ ì¹´í…Œê³ ë¦¬ë„ ìºì‹± (ë¹ ë¥¸ ì¡°íšŒìš©)
            for category in categories:
                cat_key = f"{self.namespaces['categories']}by_name:{category.get('name', '')}"
                self.cache_service.redis_set_with_expiry(cat_key, category, expire_seconds)
            
            if success:
                logging.info(f"âœ… Account categories cached: {len(categories)} items")
            
            return success
            
        except Exception as e:
            logging.error(f"âŒ Categories caching failed: {e}")
            return False
    
    def get_cached_account_categories(self) -> Optional[List[Dict]]:
        """ìºì‹œëœ ê³„ì •ê³¼ëª© ëª©ë¡ ì¡°íšŒ"""
        if not self.redis_client:
            return None
        
        try:
            key = f"{self.namespaces['categories']}all"
            cache_data = self.cache_service.redis_get_with_ttl(key)
            
            if cache_data['exists']:
                logging.info(f"ğŸ¯ Categories cache hit (TTL: {cache_data['ttl']}s)")
                return cache_data['value']['categories']
            
            return None
            
        except Exception as e:
            logging.error(f"âŒ Categories retrieval failed: {e}")
            return None
    
    def clear_namespace(self, namespace: str) -> int:
        """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  í‚¤ ì‚­ì œ"""
        if namespace not in self.namespaces:
            logging.warning(f"Unknown namespace: {namespace}")
            return 0
        
        pattern = f"{self.namespaces[namespace]}*"
        deleted_count = self.cache_service.redis_delete_pattern(pattern)
        
        if deleted_count > 0:
            logging.info(f"ğŸ—‘ï¸  Cleared {deleted_count} keys from namespace '{namespace}'")
        
        return deleted_count
    
    def get_cache_statistics(self) -> Dict:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        if not self.redis_client:
            return {"error": "Redis not connected"}
        
        try:
            stats = {}
            
            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ í‚¤ ê°œìˆ˜
            for ns_name, ns_prefix in self.namespaces.items():
                pattern = f"{ns_prefix}*"
                keys = self.redis_client.keys(pattern)
                stats[f"{ns_name}_keys"] = len(keys)
            
            # Redis ì „ì²´ ì •ë³´
            redis_info = self.cache_service.get_redis_info()
            stats.update(redis_info)
            
            return stats
            
        except Exception as e:
            return {"error": str(e)}

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
cache_service = CacheService()
performance_optimizer = PerformanceOptimizer(cache_service)
redis_cache_manager = RedisCacheManager(cache_service) 