#!/usr/bin/env python3
"""
ğŸ§¾ Simple Receipt Processor

ì‹¬í”Œí•œ ë‹¨ì¼ API ì—”ë“œí¬ì¸íŠ¸ë¡œ ì˜ìˆ˜ì¦ ì²˜ë¦¬
- Naver OCR â†’ LLM ë°ì´í„° ì¶”ì¶œ â†’ DB íŒ¨í„´ ë¶„ì„ â†’ ìµœì¢… íŒë‹¨
"""

import os
import json
import hashlib
import logging
import mysql.connector
import redis
import requests
import base64
from datetime import datetime, timedelta
from typing import Dict, Optional, List
from flask import Flask, request, jsonify
from flask_restx import Api, Resource, fields, reqparse
from flask_cors import CORS
from werkzeug.datastructures import FileStorage
from openai import OpenAI
from dotenv import load_dotenv
import re

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Flask ì•± ì„¤ì •
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

# CORS ì„¤ì • - ë‹¤ë¥¸ í¬íŠ¸ì˜ ì›¹ì„œë²„ì—ì„œ ì ‘ê·¼ í—ˆìš©
CORS(app, resources={
    r"/process": {"origins": "*"},  # ëª¨ë“  ë„ë©”ì¸ì—ì„œ /process ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ í—ˆìš©
    r"/health": {"origins": "*"}    # ëª¨ë“  ë„ë©”ì¸ì—ì„œ /health ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ í—ˆìš©
})

# Flask-RestX ì„¤ì •
api = Api(
    app,
    version='2.0',
    title='ğŸ§¾ Simple Receipt Processor',
    description='ì‹¬í”Œí•œ ì˜ìˆ˜ì¦ ìë™ ì²˜ë¦¬ API',
    doc='/'
)

# API ëª¨ë¸ ì •ì˜
receipt_model = api.model('Receipt', {
    'image': fields.Raw(required=True, description='ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ íŒŒì¼')
})

# íŒŒì¼ ì—…ë¡œë“œë¥¼ ìœ„í•œ reqparse ì •ì˜
upload_parser = api.parser()
upload_parser.add_argument('image', location='files', type=FileStorage, required=True, help='ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ íŒŒì¼ (JPG, PNG)')

response_model = api.model('ReceiptResponse', {
    'success': fields.Boolean(description='ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€'),
    'data': fields.Raw(description='ì¶”ì¶œëœ ì˜ìˆ˜ì¦ ë°ì´í„° (amount, usageDateTime, usageLocation, accountCategory, description)'),
    'reasoning': fields.Raw(description='AI íŒë‹¨ ê³¼ì • ë° ì¶”ë¡  ê·¼ê±° (5ë‹¨ê³„ ìƒì„¸ ë¶„ì„)'),
    'processing_time': fields.String(description='ì²˜ë¦¬ ì†Œìš” ì‹œê°„'),
    'cache_used': fields.Boolean(description='ìºì‹œ ì‚¬ìš© ì—¬ë¶€')
})

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
class Config:
    # OCR API
    CLOVA_OCR_API_KEY = os.getenv('CLOVA_OCR_API_KEY')
    CLOVA_OCR_ENDPOINT = os.getenv('CLOVA_OCR_ENDPOINT')
    
    # LLM API
    OPENAI_API_KEY = os.getenv('LLM_API_KEY')
    
    # Database
    DB_HOST = os.getenv('DB_HOST', 'localhost')
    DB_PORT = int(os.getenv('DB_PORT', 3306))
    DB_USER = os.getenv('DB_USER')
    DB_PASSWORD = os.getenv('DB_PASSWORD')
    DB_NAME = os.getenv('DB_NAME')

# Redis í´ë¼ì´ì–¸íŠ¸
try:
    redis_client = redis.Redis(host='localhost', port=6379, db=1, decode_responses=True)
    redis_client.ping()
    logging.info("âœ… Redis ì—°ê²° ì„±ê³µ")
except:
    redis_client = None
    logging.warning("âŒ Redis ì—°ê²° ì‹¤íŒ¨ - ìºì‹œ ì—†ì´ ë™ì‘")

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=Config.OPENAI_API_KEY) if Config.OPENAI_API_KEY else None

class ReceiptProcessor:
    """ì˜ìˆ˜ì¦ ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = Config()
        
    def get_image_hash(self, image_data: bytes) -> str:
        """ì´ë¯¸ì§€ SHA-256 í•´ì‹œ ìƒì„±"""
        return hashlib.sha256(image_data).hexdigest()
    
    def get_redis_cache(self, key: str) -> Optional[Dict]:
        """Redis ìºì‹œ ì¡°íšŒ"""
        if not redis_client:
            return None
        
        try:
            cached_data = redis_client.get(key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            logging.warning(f"Redis ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return None
    
    def set_redis_cache(self, key: str, data: Dict, expire_seconds: int = 3600):
        """Redis ìºì‹œ ì €ì¥"""
        if not redis_client:
            return
        
        try:
            redis_client.setex(key, expire_seconds, json.dumps(data, ensure_ascii=False))
        except Exception as e:
            logging.warning(f"Redis ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def call_naver_ocr(self, image_data: bytes) -> Dict:
        """ë„¤ì´ë²„ CLOVA OCR API í˜¸ì¶œ"""
        if not self.config.CLOVA_OCR_API_KEY:
            return {"error": "CLOVA OCR API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # API ìš”ì²­ ë°ì´í„°
            request_data = {
                "images": [{
                    "format": "jpg",
                    "name": "receipt",
                    "data": image_base64
                }],
                "requestId": f"receipt_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "version": "V2",
                "timestamp": int(datetime.now().timestamp() * 1000)
            }
            
            # API í—¤ë”
            headers = {
                'X-OCR-SECRET': self.config.CLOVA_OCR_API_KEY,
                "Content-Type": "application/json"
            }
            
            # API í˜¸ì¶œ
            response = requests.post(
                self.config.CLOVA_OCR_ENDPOINT,
                headers=headers,
                json=request_data,
                timeout=30
            )
            
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            logging.error(f"ë„¤ì´ë²„ OCR API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def extract_text_from_ocr(self, ocr_result: Dict) -> str:
        """OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            text_blocks = []
            
            if 'images' in ocr_result and ocr_result['images']:
                image = ocr_result['images'][0]
                if 'fields' in image:
                    for field in image['fields']:
                        if 'inferText' in field:
                            text_blocks.append(field['inferText'])
            
            return '\n'.join(text_blocks)
            
        except Exception as e:
            logging.error(f"OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def extract_data_with_llm(self, ocr_text: str) -> Dict:
        """OCR í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ"""
        cache_key = f"receipt:llm:{hashlib.md5(ocr_text.encode()).hexdigest()}"
        
        # Redis ìºì‹œ í™•ì¸
        cached_result = self.get_redis_cache(cache_key)
        if cached_result:
            logging.info("âœ… LLM ì¶”ì¶œ ìºì‹œ ì ì¤‘")
            return cached_result
        
        try:
            prompt = f"""
ë‹¤ìŒ ì˜ìˆ˜ì¦ OCR í…ìŠ¤íŠ¸ì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

"{ocr_text}"

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "amount": ìˆ«ìí˜•íƒœì˜_ì´ê¸ˆì•¡,
    "rawDateTime": "ì›ë³¸_ë‚ ì§œì‹œê°„_í…ìŠ¤íŠ¸",
    "usageLocation": "ìƒì ëª…_ë˜ëŠ”_ì‚¬ìš©ì²˜"
}}

ì¤‘ìš”í•œ ì¶”ì¶œ ê·œì¹™:
- amount: ì´ ê²°ì œ ê¸ˆì•¡ë§Œ ìˆ«ìë¡œ (ì‰¼í‘œ, ì›í™” ê¸°í˜¸ ì œê±°, ê°€ì¥ í° ê¸ˆì•¡ ìš°ì„ )
- rawDateTime: ì˜ìˆ˜ì¦ì—ì„œ ì°¾ì€ ë‚ ì§œ/ì‹œê°„ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ (ì˜ˆ: "25.1.2.19:11:30", "2025ë…„ 1ì›” 2ì¼ 19ì‹œ 11ë¶„", "01/02 19:11" ë“±)
  * ë‚ ì§œ/ì‹œê°„ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ""
  * ì—¬ëŸ¬ ë‚ ì§œê°€ ìˆìœ¼ë©´ ê°€ì¥ ìµœê·¼/ëª…í™•í•œ ê²ƒ ì„ íƒ
- usageLocation: ìƒì ëª…ì´ë‚˜ ì‚¬ìš©ì²˜ë¥¼ ì •í™•íˆ (ë¸Œëœë“œëª… ìš°ì„ , ì§€ì ëª… ì œì™¸)
- JSON í˜•ì‹ë§Œ ì‘ë‹µí•˜ê³  ë‹¤ë¥¸ ì„¤ëª… ì¶”ê°€ ê¸ˆì§€

ì¶”ì¶œ ê°€ì´ë“œ:
1. ê¸ˆì•¡: "ì´ ê¸ˆì•¡", "í•©ê³„", "ê²°ì œ ê¸ˆì•¡" ë“± ëª…ì‹œëœ ì´ì•¡ ìš°ì„ 
2. ë‚ ì§œ: "ê±°ë˜ì¼ì‹œ", "ê²°ì œì¼ì‹œ", "ì˜ìˆ˜ì¦ì¼ì‹œ" ë“± ëª…ì‹œëœ ì‹œê°„ ìš°ì„ 
3. ìƒì : "ìƒí˜¸ëª…", "ë§¤ì¥ëª…", "ë¸Œëœë“œëª…" ë“± ëª…ì‹œëœ ì´ë¦„ ìš°ì„ 

ë‚ ì§œ/ì‹œê°„ ì¶”ì¶œ ì˜ˆì‹œ:
- "25.1.2.19:11:30" â†’ rawDateTime: "25.1.2.19:11:30"
- "2025ë…„ 1ì›” 2ì¼ 19ì‹œ 11ë¶„ 30ì´ˆ" â†’ rawDateTime: "2025ë…„ 1ì›” 2ì¼ 19ì‹œ 11ë¶„ 30ì´ˆ"
- "2025/01/02 19:11" â†’ rawDateTime: "2025/01/02 19:11"
- "19:11:30" â†’ rawDateTime: "19:11:30"
- ë‚ ì§œ/ì‹œê°„ ì—†ìŒ â†’ rawDateTime: ""
"""
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            logging.info(f"LLM ì›ë³¸ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {result}")
            
            # ë‚ ì§œ/ì‹œê°„ ì •í˜•í™” ì ìš©
            raw_datetime = result.get('rawDateTime', '')
            normalized_datetime = self.normalize_datetime(raw_datetime)
            result['usageDateTime'] = normalized_datetime
            
            # ë°ì´í„° ê²€ì¦ ë° ë³´ì •
            amount = result.get('amount', 0)
            if isinstance(amount, str):
                # ë¬¸ìì—´ì¸ ê²½ìš° ìˆ«ìë§Œ ì¶”ì¶œ
                amount = re.sub(r'[^\d]', '', amount)
                result['amount'] = int(amount) if amount else 0
            
            usage_location = result.get('usageLocation', '')
            if not usage_location or len(usage_location.strip()) == 0:
                result['usageLocation'] = 'ë¯¸í™•ì¸'
            
            # rawDateTimeì€ ë””ë²„ê¹…ìš©ìœ¼ë¡œ ìœ ì§€, ìµœì¢… ì‘ë‹µì—ì„œëŠ” ì œì™¸
            logging.info(f"ë‚ ì§œ ì •í˜•í™” ì™„ë£Œ: '{raw_datetime}' â†’ '{normalized_datetime}'")
            logging.info(f"ë°ì´í„° ê²€ì¦ ì™„ë£Œ: ê¸ˆì•¡={result['amount']}, ì‚¬ìš©ì²˜={result['usageLocation']}")
            
            # ìºì‹œ ì €ì¥
            self.set_redis_cache(cache_key, result, 3600)  # 1ì‹œê°„
            return result
            
        except Exception as e:
            logging.error(f"LLM ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def get_db_patterns(self, usage_location: str) -> List[Dict]:
        """êµ¬ë§¤ì²˜ ê¸°ë°˜ìœ¼ë¡œ ê³¼ê±° íŒ¨í„´ ì¡°íšŒ"""
        cache_key = f"receipt:pattern:{hashlib.md5(usage_location.encode()).hexdigest()}"
        
        # Redis ìºì‹œ í™•ì¸
        cached_patterns = self.get_redis_cache(cache_key)
        if cached_patterns:
            logging.info(f"âœ… DB íŒ¨í„´ ìºì‹œ ì ì¤‘: {len(cached_patterns)} íŒ¨í„´")
            return cached_patterns
        
        try:
            conn = mysql.connector.connect(
                host=self.config.DB_HOST,
                port=self.config.DB_PORT,
                user=self.config.DB_USER,
                password=self.config.DB_PASSWORD,
                database=self.config.DB_NAME
            )
            cursor = conn.cursor(dictionary=True)
            
            # usageLocation í•„ë“œì—ì„œ êµ¬ë§¤ì²˜ ê¸°ë°˜ íŒ¨í„´ ì¡°íšŒ (ì •í™•ë„ í–¥ìƒ)
            query = """
            SELECT accountCategory, description, COUNT(*) as frequency,
                   CASE 
                       WHEN usageLocation = %s THEN 3
                       WHEN usageLocation LIKE %s THEN 2
                       WHEN usageLocation LIKE %s THEN 1
                       ELSE 0
                   END as relevance_score
            FROM expense_items 
            WHERE (usageLocation = %s OR usageLocation LIKE %s OR usageLocation LIKE %s)
              AND accountCategory IS NOT NULL
            GROUP BY accountCategory, description
            ORDER BY relevance_score DESC, frequency DESC
            LIMIT 10
            """
            
            exact_match = usage_location
            starts_with = f"{usage_location}%"
            contains = f"%{usage_location}%"
            
            cursor.execute(query, (exact_match, starts_with, contains, exact_match, starts_with, contains))
            patterns = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            # Redisì— ìºì‹± (30ë¶„)
            self.set_redis_cache(cache_key, patterns, 1800)
            
            logging.info(f"ğŸ“Š DBì—ì„œ '{usage_location}' íŒ¨í„´ {len(patterns)}ê°œ ì¡°íšŒ")
            return patterns
            
        except Exception as e:
            logging.error(f"âŒ DB íŒ¨í„´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def read_account_category_guide(self) -> str:
        """ê³„ì •ê³¼ëª© ê°€ì´ë“œ ë¬¸ì„œ ì½ê¸°"""
        try:
            with open('account_category_list.md', 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logging.error(f"ê³„ì •ê³¼ëª© ê°€ì´ë“œ ì½ê¸° ì‹¤íŒ¨: {e}")
            return ""
    
    def format_db_patterns(self, patterns: List[Dict]) -> str:
        """DB íŒ¨í„´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not patterns:
            return "í•´ë‹¹ ì‚¬ìš©ì²˜ì— ëŒ€í•œ ê³¼ê±° ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        formatted = []
        total_frequency = sum(p['frequency'] for p in patterns)
        
        for i, pattern in enumerate(patterns[:5]):  # ìƒìœ„ 5ê°œë§Œ
            percentage = (pattern['frequency'] / total_frequency * 100) if total_frequency > 0 else 0
            relevance = "ì •í™•" if pattern.get('relevance_score', 0) >= 2 else "ìœ ì‚¬"
            formatted.append(f"{i+1}. {pattern['accountCategory']}: {pattern['description']} (ì‚¬ìš©íšŸìˆ˜: {pattern['frequency']}, ë¹„ìœ¨: {percentage:.1f}%, ë§¤ì¹­: {relevance})")
        
        return "\n".join(formatted)
    
    def final_judgment_with_llm(self, extracted_data: Dict, db_patterns: List[Dict], guide_text: str) -> Dict:
        """LLMìœ¼ë¡œ ìµœì¢… ê³„ì •ê³¼ëª© ë° ì§€ì¶œìš©ë„ íŒë‹¨"""
        cache_key = f"receipt:final:{hashlib.md5(str(extracted_data).encode()).hexdigest()}"
        
        # Redis ìºì‹œ í™•ì¸
        cached_result = self.get_redis_cache(cache_key)
        if cached_result:
            logging.info("âœ… ìµœì¢… íŒë‹¨ ìºì‹œ ì ì¤‘")
            return cached_result
        
        # ë‚ ì§œ/ì‹œê°„ ë¶„ì„
        datetime_analysis = self.analyze_datetime(extracted_data.get('usageDateTime', ''))
        
        pattern_summary = f"""
ğŸ“Š ê³¼ê±° íŒ¨í„´ ë¶„ì„ (usageLocation: '{extracted_data.get('usageLocation', '')}'):
{self.format_db_patterns(db_patterns)}
""" if db_patterns else "ğŸ“Š ê³¼ê±° íŒ¨í„´: í•´ë‹¹ ì‚¬ìš©ì²˜ì— ëŒ€í•œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            prompt = f"""
ì˜ìˆ˜ì¦ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê³„ì •ê³¼ëª©ê³¼ ì§€ì¶œí•­ëª©ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ğŸ“‹ ì¶”ì¶œëœ ë°ì´í„°:
- ê¸ˆì•¡: {extracted_data.get('amount', 0):,}ì›
- ì‚¬ìš©ì¼ì‹œ: {extracted_data.get('usageDateTime', '')}
- ì‚¬ìš©ì²˜: {extracted_data.get('usageLocation', '')}

ğŸ• ì‹œê°„ ë¶„ì„ ì •ë³´:
- ìš”ì¼: {datetime_analysis['weekday']} ({datetime_analysis['day_type']})
- ì‹œê°„: {datetime_analysis['hour']}ì‹œ ({datetime_analysis['time_period']})
- ê·¼ë¬´êµ¬ë¶„: {datetime_analysis['work_context']}
- ì£¼ë§ì—¬ë¶€: {'ì˜ˆ' if datetime_analysis['is_weekend'] else 'ì•„ë‹ˆì˜¤'}
- íŠ¹ê·¼/ì•¼ê·¼: {'ì˜ˆ' if datetime_analysis['is_overtime'] else 'ì•„ë‹ˆì˜¤'}

{pattern_summary}

ğŸ“š ê³„ì •ê³¼ëª© ê°€ì´ë“œ (í•œêµ­ ê¸°ì—… ì‹¤ë¬´ìš©):
{guide_text[:2000]}...

ğŸ¯ **ì •í™•í•œ íŒë‹¨ ê¸°ì¤€**:

1. **ê¸ˆì•¡ ê¸°ë°˜ íŒë‹¨**:
   - 1,000ì› ë¯¸ë§Œ: ê°„ì‹, ì»¤í”¼, ìŒë£Œ
   - 1,000-5,000ì›: ì ì‹¬ì‹ëŒ€, ê°„ì‹
   - 5,000-20,000ì›: ì‹ëŒ€, ì—…ë¬´ìš©í’ˆ
   - 20,000ì› ì´ìƒ: íšŒì‹, ì¥ë¹„, ì†Œí”„íŠ¸ì›¨ì–´

2. **ì‹œê°„ëŒ€ë³„ Description ìƒì„±**:
   **í‰ì¼ (ì›”~ê¸ˆ)**:
   - 06:00-11:00 (ì˜¤ì „) â†’ "ì¡°ì‹", "ì˜¤ì „ ì»¤í”¼"
   - 11:00-14:00 (ì ì‹¬) â†’ "ì ì‹¬ì‹ëŒ€", "ì ì‹¬ ì»¤í”¼" 
   - 14:00-18:00 (ì˜¤í›„) â†’ "ì˜¤í›„ ì»¤í”¼", "ì—…ë¬´ ê°„ì‹"
   - 18:00-22:00 (ì•¼ê·¼) â†’ "ì•¼ê·¼ì‹ëŒ€", "ì•¼ê·¼ ì»¤í”¼", "ì•¼ê·¼ ë°°ë‹¬"
   - 22:00-06:00 (ì‹¬ì•¼) â†’ "ì‹¬ì•¼ ì•¼ê·¼ì‹ëŒ€"

   **í† ìš”ì¼**: ëª¨ë“  ì‹œê°„ëŒ€ â†’ "í† ìš” íŠ¹ê·¼ ì‹ëŒ€", "í† ìš” íŠ¹ê·¼ ì»¤í”¼"
   **ì¼ìš”ì¼**: ëª¨ë“  ì‹œê°„ëŒ€ â†’ "ì¼ìš” íŠ¹ê·¼ ì‹ëŒ€", "ì¼ìš” íŠ¹ê·¼ ì»¤í”¼"

3. **ë¸Œëœë“œë³„ ìš°ì„ ìˆœìœ„**:
   - ì •í™•í•œ ë¸Œëœë“œëª… ë§¤ì¹­ ìš°ì„ 
   - ìœ ì‚¬í•œ ë¸Œëœë“œëª… ì°¨ìˆœìœ„
   - ì¼ë°˜ì ì¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ìµœí›„

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "amount": {extracted_data.get('amount', 0)},
    "usageDateTime": "{extracted_data.get('usageDateTime', '')}",
    "usageLocation": "{extracted_data.get('usageLocation', '')}",
    "accountCategory": "ìµœì¢…_ê²°ì •ëœ_ê³„ì •ê³¼ëª©",
    "description": "ì‹œê°„ë¶„ì„_ê¸°ë°˜_êµ¬ì²´ì _ì§€ì¶œí•­ëª©",
    "reasoning": {{
        "step1_brand_analysis": "í•œêµ­ ë¸Œëœë“œ ì‹ë³„ ë° ë¶„ì„ ê²°ê³¼",
        "step2_time_analysis": "ì •í™•í•œ ì‹œê°„ëŒ€ ë¶„ì„ - {datetime_analysis['weekday']} {datetime_analysis['hour']}ì‹œ ({datetime_analysis['work_context']})",
        "step3_db_patterns": "DB íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë° í™œìš©ë„",
        "step4_guide_matching": "ê°€ì´ë“œ ë¬¸ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼",
        "step5_final_decision": "ìµœì¢… íŒë‹¨ ê·¼ê±° (ê¸ˆì•¡+ì‹œê°„+ë¸Œëœë“œ ì¢…í•© ë¶„ì„)",
        "confidence_level": "ë†’ìŒ/ë³´í†µ/ë‚®ìŒ"
    }}
}}

ì¤‘ìš”:
- descriptionì€ ì‹œê°„ ë¶„ì„ ì •ë³´({datetime_analysis['work_context']})ë¥¼ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”
- ì¶”ì¸¡ì„± ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš” (ëª©ì ì§€, íšŒì˜ ë“±)
- ì‹¤ì œ ì¶”ì¶œëœ ë°ì´í„°ì™€ ì‹œê°„ ë¶„ì„ë§Œ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”
- ê¸ˆì•¡ê³¼ ì‹œê°„ëŒ€ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ë¶„ë¥˜ë¥¼ ê²°ì •í•˜ì„¸ìš”
"""
            
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            logging.info(f"LLM ìµœì¢… íŒë‹¨ ì™„ë£Œ: {result}")
            
            # ìºì‹œ ì €ì¥
            self.set_redis_cache(cache_key, result, 1800)  # 30ë¶„
            return result
            
        except Exception as e:
            logging.error(f"LLM ìµœì¢… íŒë‹¨ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def process_receipt(self, image_data: bytes) -> Dict:
        """ì˜ìˆ˜ì¦ ì²˜ë¦¬ ë©”ì¸ í”„ë¡œì„¸ìŠ¤"""
        start_time = datetime.now()
        cache_used = False
        
        try:
            # 1. ì´ë¯¸ì§€ í•´ì‹œ ìƒì„±
            image_hash = self.get_image_hash(image_data)
            cache_key = f"receipt:complete:{image_hash}"
            
            # 2. ì „ì²´ ê²°ê³¼ ìºì‹œ í™•ì¸
            cached_result = self.get_redis_cache(cache_key)
            if cached_result:
                cache_used = True
                processing_time = (datetime.now() - start_time).total_seconds()
                return {
                    "success": True,
                    "data": cached_result,
                    "processing_time": f"{processing_time:.2f}s",
                    "cache_used": cache_used
                }
            
            # 3. OCR ì²˜ë¦¬ (ìºì‹œ í™•ì¸)
            ocr_cache_key = f"receipt:ocr:{image_hash}"
            ocr_result = self.get_redis_cache(ocr_cache_key)
            
            if not ocr_result:
                logging.info("ğŸ“¸ ë„¤ì´ë²„ OCR ì²˜ë¦¬ ì¤‘...")
                ocr_result = self.call_naver_ocr(image_data)
                if "error" not in ocr_result:
                    self.set_redis_cache(ocr_cache_key, ocr_result, 86400)  # 24ì‹œê°„
            else:
                logging.info("ğŸ¯ OCR ìºì‹œ ì ì¤‘")
                cache_used = True
            
            if "error" in ocr_result:
                return {"success": False, "error": ocr_result["error"]}
            
            # 4. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
            ocr_text = self.extract_text_from_ocr(ocr_result)
            if not ocr_text:
                return {"success": False, "error": "OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"}
            
            # 5. LLM ë°ì´í„° ì¶”ì¶œ (ìºì‹œ í™•ì¸)
            text_hash = hashlib.md5(ocr_text.encode()).hexdigest()
            llm_cache_key = f"receipt:llm:{text_hash}"
            extracted_data = self.get_redis_cache(llm_cache_key)
            
            if not extracted_data:
                logging.info("ğŸ¤– LLM ë°ì´í„° ì¶”ì¶œ ì¤‘...")
                extracted_data = self.extract_data_with_llm(ocr_text)
                if "error" not in extracted_data:
                    self.set_redis_cache(llm_cache_key, extracted_data, 7200)  # 2ì‹œê°„
            else:
                logging.info("ğŸ¯ LLM ìºì‹œ ì ì¤‘")
                cache_used = True
            
            if "error" in extracted_data:
                return {"success": False, "error": extracted_data["error"]}
            
            # 6. DB íŒ¨í„´ ì¡°íšŒ (ìºì‹œ í™•ì¸)
            usage_location = extracted_data.get('usageLocation', '')
            pattern_cache_key = f"receipt:pattern:{hashlib.md5(usage_location.encode()).hexdigest()}"
            db_patterns = self.get_redis_cache(pattern_cache_key)
            
            if not db_patterns:
                logging.info("ğŸ—„ï¸ DB íŒ¨í„´ ì¡°íšŒ ì¤‘...")
                db_patterns = self.get_db_patterns(usage_location)
                self.set_redis_cache(pattern_cache_key, db_patterns, 1800)  # 30ë¶„
            else:
                logging.info("ğŸ¯ íŒ¨í„´ ìºì‹œ ì ì¤‘")
                cache_used = True
            
            # 7. ê³„ì •ê³¼ëª© ê°€ì´ë“œ ì½ê¸°
            guide_text = self.read_account_category_guide()
            
            # 8. LLM ìµœì¢… íŒë‹¨
            logging.info("ğŸ§  LLM ìµœì¢… íŒë‹¨ ì¤‘...")
            final_result = self.final_judgment_with_llm(extracted_data, db_patterns, guide_text)
            
            if "error" in final_result:
                return {"success": False, "error": final_result["error"]}
            
            # 9. ì „ì²´ ê²°ê³¼ ìºì‹œ ì €ì¥
            self.set_redis_cache(cache_key, final_result, 3600)  # 1ì‹œê°„
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ìµœì¢… ê²°ê³¼ ë°˜í™˜
            result = {
                "success": True,
                "data": {
                    "amount": final_result.get("amount"),
                    "usageDateTime": final_result.get("usageDateTime"), 
                    "usageLocation": final_result.get("usageLocation"),
                    "accountCategory": final_result.get("accountCategory"),
                    "description": final_result.get("description")
                },
                "reasoning": final_result.get("reasoning", {}),
                "processing_time": f"{processing_time:.2f}s",
                "cache_used": cache_used
            }
            
            return result
            
        except Exception as e:
            logging.error(f"ì˜ìˆ˜ì¦ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    def normalize_datetime(self, datetime_str: str) -> str:
        """ë‹¤ì–‘í•œ ë‚ ì§œ/ì‹œê°„ í˜•ì‹ì„ í‘œì¤€ í˜•ì‹(YYYY-MM-DD HH:mm:ss)ìœ¼ë¡œ ì •í˜•í™”"""
        if not datetime_str or datetime_str.strip() == "":
            return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (ì¤‘ê°„ì  Â· ë³´ì¡´)
        cleaned = re.sub(r'[^\d\-/.:ë…„ì›”ì¼ì‹œë¶„ì´ˆÂ·]', ' ', datetime_str.strip())
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ë“¤
        patterns = [
            # 24.12.18Â·18:31:21 í˜•íƒœ (YY.MM.DDÂ·HH:mm:ss) - ì¤‘ê°„ì  í¬í•¨
            (r'(\d{2})\.(\d{1,2})\.(\d{1,2})[Â·\s]+(\d{1,2}):(\d{2}):(\d{2})', 
             lambda m: f"20{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:{m.group(6)}"),
            
            # 25.1.2.19:11:30 í˜•íƒœ (YY.M.D.HH:mm:ss) - ì ìœ¼ë¡œ êµ¬ë¶„
            (r'(\d{2})\.(\d{1,2})\.(\d{1,2})\.(\d{1,2}):(\d{2}):(\d{2})', 
             lambda m: f"20{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:{m.group(6)}"),
            
            # 2025.1.2 19:11:30 í˜•íƒœ (YYYY.M.D HH:mm:ss)
            (r'(\d{4})\.(\d{1,2})\.(\d{1,2})\s+(\d{1,2}):(\d{2}):(\d{2})', 
             lambda m: f"{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:{m.group(6)}"),
            
            # 2025/01/02 19:11:30 í˜•íƒœ (YYYY/MM/DD HH:mm:ss)
            (r'(\d{4})/(\d{1,2})/(\d{1,2})\s+(\d{1,2}):(\d{2}):(\d{2})', 
             lambda m: f"{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:{m.group(6)}"),
            
            # 25-01-02 19:11 í˜•íƒœ (YY-MM-DD HH:mm)
            (r'(\d{2})-(\d{1,2})-(\d{1,2})\s+(\d{1,2}):(\d{2})', 
             lambda m: f"20{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:00"),
            
            # 2025ë…„ 1ì›” 2ì¼ 19ì‹œ 11ë¶„ 30ì´ˆ í˜•íƒœ
            (r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ\s*(\d{1,2})ë¶„\s*(\d{1,2})ì´ˆ', 
             lambda m: f"{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:{m.group(6)}"),
            
            # 2025ë…„ 1ì›” 2ì¼ 19ì‹œ 11ë¶„ í˜•íƒœ
            (r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*(\d{1,2})ì‹œ\s*(\d{1,2})ë¶„', 
             lambda m: f"{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} {m.group(4):0>2}:{m.group(5)}:00"),
            
            # 01/02 19:11 í˜•íƒœ (MM/DD HH:mm) - ì˜¬í•´ë¡œ ê°€ì •
            (r'(\d{1,2})/(\d{1,2})\s+(\d{1,2}):(\d{2})', 
             lambda m: f"{datetime.now().year}-{m.group(1):0>2}-{m.group(2):0>2} {m.group(3):0>2}:{m.group(4)}:00"),
            
            # 19:11:30 í˜•íƒœ (HH:mm:ss) - ì˜¤ëŠ˜ ë‚ ì§œë¡œ ê°€ì •
            (r'^(\d{1,2}):(\d{2}):(\d{2})$', 
             lambda m: f"{datetime.now().strftime('%Y-%m-%d')} {m.group(1):0>2}:{m.group(2)}:{m.group(3)}"),
            
            # 19:11 í˜•íƒœ (HH:mm) - ì˜¤ëŠ˜ ë‚ ì§œë¡œ ê°€ì •
            (r'^(\d{1,2}):(\d{2})$', 
             lambda m: f"{datetime.now().strftime('%Y-%m-%d')} {m.group(1):0>2}:{m.group(2)}:00"),
            
            # 2025-01-02 í˜•íƒœ (YYYY-MM-DD) - ê¸°ë³¸ ì‹œê°„ 12:00:00
            (r'^(\d{4})-(\d{1,2})-(\d{1,2})$', 
             lambda m: f"{m.group(1)}-{m.group(2):0>2}-{m.group(3):0>2} 12:00:00"),
        ]
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹œë„
        for pattern, formatter in patterns:
            match = re.search(pattern, cleaned)
            if match:
                try:
                    result = formatter(match)
                    # ìœ íš¨í•œ ë‚ ì§œì¸ì§€ ê²€ì¦
                    datetime.strptime(result, '%Y-%m-%d %H:%M:%S')
                    logging.info(f"ë‚ ì§œ ì •í˜•í™” ì„±ê³µ: '{datetime_str}' â†’ '{result}'")
                    return result
                except ValueError:
                    continue
        
        # ëª¨ë“  íŒ¨í„´ì´ ì‹¤íŒ¨í•˜ë©´ í˜„ì¬ ì‹œê°„ ë°˜í™˜
        fallback = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        logging.warning(f"ë‚ ì§œ ì •í˜•í™” ì‹¤íŒ¨, í˜„ì¬ ì‹œê°„ ì‚¬ìš©: '{datetime_str}' â†’ '{fallback}'")
        return fallback
    
    def analyze_datetime(self, datetime_str: str) -> dict:
        """ë‚ ì§œ/ì‹œê°„ì„ ë¶„ì„í•˜ì—¬ ìš”ì¼, ì‹œê°„ëŒ€, ê·¼ë¬´ ìœ í˜• ë“±ì„ ë°˜í™˜"""
        try:
            dt = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')
            
            # ìš”ì¼ ë¶„ì„ (0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼)
            weekday = dt.weekday()
            weekday_names = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
            
            # ì‹œê°„ëŒ€ ë¶„ì„
            hour = dt.hour
            if 6 <= hour < 11:
                time_period = "ì˜¤ì „"
                work_type = "ì¡°ì‹/ì˜¤ì „ ì—…ë¬´"
            elif 11 <= hour < 14:
                time_period = "ì ì‹¬"
                work_type = "ì ì‹¬ì‹ëŒ€"
            elif 14 <= hour < 18:
                time_period = "ì˜¤í›„"
                work_type = "ì˜¤í›„ ì—…ë¬´"
            elif 18 <= hour < 22:
                time_period = "ì•¼ê·¼"
                work_type = "ì•¼ê·¼ì‹ëŒ€"
            else:  # 22ì‹œ ì´í›„ ë˜ëŠ” 6ì‹œ ì´ì „
                time_period = "ì‹¬ì•¼"
                work_type = "ì‹¬ì•¼ ì•¼ê·¼ì‹ëŒ€"
            
            # ê·¼ë¬´ì¼ êµ¬ë¶„
            if weekday < 5:  # í‰ì¼ (ì›”~ê¸ˆ)
                day_type = "í‰ì¼"
                if time_period in ["ì•¼ê·¼", "ì‹¬ì•¼"]:
                    work_context = f"í‰ì¼ {work_type}"
                else:
                    work_context = f"í‰ì¼ {work_type}"
            elif weekday == 5:  # í† ìš”ì¼
                day_type = "í† ìš”ì¼"
                work_context = f"í† ìš” íŠ¹ê·¼ {work_type.replace('ì‹ëŒ€', 'ì‹ëŒ€')}"
            else:  # ì¼ìš”ì¼
                day_type = "ì¼ìš”ì¼"
                work_context = f"ì¼ìš” íŠ¹ê·¼ {work_type.replace('ì‹ëŒ€', 'ì‹ëŒ€')}"
            
            return {
                "weekday": weekday_names[weekday],
                "day_type": day_type,
                "hour": hour,
                "time_period": time_period,
                "work_type": work_type,
                "work_context": work_context,
                "is_weekend": weekday >= 5,
                "is_overtime": time_period in ["ì•¼ê·¼", "ì‹¬ì•¼"] or weekday >= 5
            }
        
        except Exception as e:
            logging.error(f"ë‚ ì§œ/ì‹œê°„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "weekday": "ì•Œ ìˆ˜ ì—†ìŒ",
                "day_type": "ì•Œ ìˆ˜ ì—†ìŒ", 
                "hour": 12,
                "time_period": "ì ì‹¬",
                "work_type": "ì ì‹¬ì‹ëŒ€",
                "work_context": "ê¸°ë³¸ ì‹ëŒ€",
                "is_weekend": False,
                "is_overtime": False
            }

# ì „ì—­ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
processor = ReceiptProcessor()

@api.route('/process')
class ReceiptProcess(Resource):
    @api.expect(upload_parser)
    @api.marshal_with(response_model) # type: ignore
    def post(self):
        """
        ğŸ§¾ **ì˜ìˆ˜ì¦ ìë™ ì²˜ë¦¬**
        
        ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ OCR â†’ LLM â†’ DB íŒ¨í„´ ë¶„ì„ì„ í†µí•´
        ì™„ì„±ëœ ê²½ë¹„ ë°ì´í„°(ê¸ˆì•¡, ì¼ì, ê³„ì •ê³¼ëª©, ì§€ì¶œí•­ëª©, ì‚¬ìš©ì²˜)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        **ì²˜ë¦¬ ê³¼ì •:**
        1. ğŸ“¸ ë„¤ì´ë²„ CLOVA OCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        2. ğŸ¤– OpenAI LLMìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
        3. ğŸ—„ï¸ DBì—ì„œ ë™ì¼ ì‚¬ìš©ì²˜ íŒ¨í„´ ì¡°íšŒ
        4. ğŸ“š ê³„ì •ê³¼ëª© ê°€ì´ë“œ ë¬¸ì„œ ì°¸ì¡°
        5. ğŸ§  LLMìœ¼ë¡œ ìµœì¢… ê³„ì •ê³¼ëª© ë° ì§€ì¶œí•­ëª© ê²°ì •
        
        **ìºì‹±:** 
        - OCR ê²°ê³¼: 24ì‹œê°„
        - LLM ì¶”ì¶œ: 2ì‹œê°„  
        - DB íŒ¨í„´: 30ë¶„
        - ì „ì²´ ê²°ê³¼: 1ì‹œê°„
        """
        try:
            # íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
            if 'image' not in request.files:
                return {"success": False, "error": "ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}, 400
            
            file = request.files['image']
            if file.filename == '':
                return {"success": False, "error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}, 400
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
            if not file.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                return {"success": False, "error": "PNG, JPG, JPEG íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤"}, 400
            
            # ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
            image_data = file.read()
            if len(image_data) == 0:
                return {"success": False, "error": "ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤"}, 400
            
            # ì˜ìˆ˜ì¦ ì²˜ë¦¬
            result = processor.process_receipt(image_data)
            
            if result["success"]:
                return result, 200
            else:
                return result, 500
                
        except Exception as e:
            logging.error(f"API ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}, 500

@api.route('/health')
class Health(Resource):
    def get(self):
        """ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        try:
            status = {
                "status": "healthy",
                "timestamp": datetime.now().isoformat(),
                "services": {
                    "redis": redis_client is not None,
                    "openai": openai_client is not None,
                    "clova_ocr": Config.CLOVA_OCR_API_KEY is not None,
                    "database": all([
                        Config.DB_HOST, Config.DB_USER, 
                        Config.DB_PASSWORD, Config.DB_NAME
                    ])
                }
            }
            
            # Redis ì—°ê²° í…ŒìŠ¤íŠ¸
            if redis_client:
                try:
                    redis_client.ping()
                    status["services"]["redis_ping"] = True
                except:
                    status["services"]["redis_ping"] = False
            
            return status, 200
            
        except Exception as e:
            return {"status": "error", "error": str(e)}, 500

if __name__ == '__main__':
    logging.info("ğŸš€ Simple Receipt Processor ì‹œì‘")
    logging.info(f"ğŸ“Š Redis ìƒíƒœ: {'ì—°ê²°ë¨' if redis_client else 'ë¹„í™œì„±í™”'}")
    logging.info(f"ğŸ¤– OpenAI ìƒíƒœ: {'ì—°ê²°ë¨' if openai_client else 'ë¹„í™œì„±í™”'}")
    logging.info(f"ğŸ“¸ CLOVA OCR ìƒíƒœ: {'ì„¤ì •ë¨' if Config.CLOVA_OCR_API_KEY else 'ë¯¸ì„¤ì •'}")
    
    app.run(
        host='0.0.0.0',
        port=5001,
        debug=True
    ) 